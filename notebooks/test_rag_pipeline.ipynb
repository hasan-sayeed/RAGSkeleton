{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set Up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# test_rag_pipeline.ipynb\n",
    "# Import necessary modules\n",
    "from rag_skeleton.data_processing import DataProcessor\n",
    "from rag_skeleton.retrieval import DocumentRetriever\n",
    "from rag_skeleton.rag import RAGPipeline\n",
    "\n",
    "# Initialize paths and model names\n",
    "data_path = \"data/raw\"  # Path where your PDFs are stored\n",
    "vectordb_path = \"vectordb\"  # Path for vector database\n",
    "embedding_model_name = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Loading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load PDFs and inspect content\n",
    "#processor = DataProcessor(data_path=data_path)\n",
    "#documents = processor.load_documents(enrich_metadata=True)  # Enable metadata enrichment\n",
    "\n",
    "#print(\"Loaded Documents:\")\n",
    "#for i, doc in enumerate(documents[:3]):  # Display the first 3 documents for brevity\n",
    "#    print(f\"Document {i+1}:\")\n",
    "#    print(\"Content:\", doc.page_content[:500])  # Show the first 500 characters of the content\n",
    "#    print(\"Metadata:\", doc.metadata)\n",
    "#    print(\"\\n---\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Loading json transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "\n",
    "def load_whisper_json_transcripts(json_dir):\n",
    "    docs = []\n",
    "    for json_path in Path(json_dir).glob(\"*.json\"):\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            page_content = data[\"text\"]\n",
    "            metadata = {\n",
    "                \"video_id\": data.get(\"video_id\", json_path.stem),\n",
    "                \"segments\": data.get(\"segments\", []),\n",
    "                \"source\": str(json_path)\n",
    "            }\n",
    "            docs.append(Document(page_content=page_content, metadata=metadata))\n",
    "    return docs\n",
    "\n",
    "documents = load_whisper_json_transcripts(\"G:/My Drive/teaching/RAG_AI_Tutor/AskSparks/transcripts_lectures_large\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test Retriever for Context Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Deleted existing vector DB at vectordb\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Be very careful with this! It deletes your previous vector DB\n",
    "if os.path.exists(vectordb_path):\n",
    "    shutil.rmtree(vectordb_path)\n",
    "    print(f\"ðŸ§¹ Deleted existing vector DB at {vectordb_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Database default_database not found for tenant default_tenant. Are you sure it exists?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 2: Index documents into ChromaDB\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m retriever = \u001b[43mDocumentRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectordb_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvectordb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m retriever.index_documents(documents)  \u001b[38;5;66;03m# <-- Make sure this is run at least once\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Vector store built and documents indexed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\My Drive\\teaching\\RAG_AI_Tutor\\AskSparks\\rag_skeleton\\src\\rag_skeleton\\retrieval.py:23\u001b[39m, in \u001b[36mDocumentRetriever.__init__\u001b[39m\u001b[34m(self, vectordb_path, embedding_model_name)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.vectordb_path = vectordb_path\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.embedding = HuggingFaceEmbeddings(model_name=embedding_model_name, model_kwargs={\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m})   \u001b[38;5;66;03m# https://github.com/langchain-ai/langchain/issues/6080#issuecomment-1963311548\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mself\u001b[39m.vector_store = \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectordb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:313\u001b[39m, in \u001b[36mChroma.__init__\u001b[39m\u001b[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn, create_collection_if_not_exists)\u001b[39m\n\u001b[32m    311\u001b[39m         _client_settings = chromadb.config.Settings()\n\u001b[32m    312\u001b[39m     \u001b[38;5;28mself\u001b[39m._client_settings = _client_settings\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28mself\u001b[39m._client = \u001b[43mchromadb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_client_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m     \u001b[38;5;28mself\u001b[39m._persist_directory = (\n\u001b[32m    315\u001b[39m         _client_settings.persist_directory \u001b[38;5;129;01mor\u001b[39;00m persist_directory\n\u001b[32m    316\u001b[39m     )\n\u001b[32m    318\u001b[39m \u001b[38;5;28mself\u001b[39m._embedding_function = embedding_function\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\chromadb\\__init__.py:334\u001b[39m, in \u001b[36mClient\u001b[39m\u001b[34m(settings, tenant, database)\u001b[39m\n\u001b[32m    331\u001b[39m tenant = \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[32m    332\u001b[39m database = \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\chromadb\\api\\client.py:80\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, tenant, database, settings)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Create an admin client for verifying that databases and tenants exist\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m._admin_client = AdminClient.from_system(\u001b[38;5;28mself\u001b[39m._system)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_tenant_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mself\u001b[39m._submit_client_start_event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\chromadb\\api\\client.py:431\u001b[39m, in \u001b[36mClient._validate_tenant_database\u001b[39m\u001b[34m(self, tenant, database)\u001b[39m\n\u001b[32m    426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    427\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not connect to tenant \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtenant\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Are you sure it exists?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m     )\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_admin_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    434\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to a Chroma server. Are you sure it is running?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    435\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\chromadb\\api\\client.py:453\u001b[39m, in \u001b[36mAdminClient.get_database\u001b[39m\u001b[34m(self, name, tenant)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_database\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, tenant: \u001b[38;5;28mstr\u001b[39m = DEFAULT_TENANT) -> Database:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:150\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity < granularity:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\chromadb\\api\\segment.py:158\u001b[39m, in \u001b[36mSegmentAPI.get_database\u001b[39m\u001b[34m(self, name, tenant)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSegmentAPI.get_database\u001b[39m\u001b[33m\"\u001b[39m, OpenTelemetryGranularity.OPERATION)\n\u001b[32m    156\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_database\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, tenant: \u001b[38;5;28mstr\u001b[39m = DEFAULT_TENANT) -> t.Database:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sysdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\RAG_AI_Tutor\\ask_env\\Lib\\site-packages\\chromadb\\db\\mixins\\sysdb.py:99\u001b[39m, in \u001b[36mSqlSysDB.get_database\u001b[39m\u001b[34m(self, name, tenant)\u001b[39m\n\u001b[32m     97\u001b[39m row = cur.execute(sql, params).fetchone()\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m row:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[32m    100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found for tenant \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtenant\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Are you sure it exists?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m     )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[32m    104\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found for tenant \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtenant\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Are you sure it exists?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    105\u001b[39m     )\n",
      "\u001b[31mNotFoundError\u001b[39m: Database default_database not found for tenant default_tenant. Are you sure it exists?"
     ]
    }
   ],
   "source": [
    "# Step 2: Index documents into ChromaDB\n",
    "retriever = DocumentRetriever(vectordb_path=vectordb_path, embedding_model_name=embedding_model_name)\n",
    "retriever.index_documents(documents)  # <-- Make sure this is run at least once\n",
    "\n",
    "print(\"âœ… Vector store built and documents indexed.\")\n",
    "\n",
    "\n",
    "# Define a sample question\n",
    "question = \"Why do metals become harder with smaller grain size?\"\n",
    "\n",
    "# Retrieve relevant documents\n",
    "retrieved_docs = retriever.get_retriever().invoke(question)\n",
    "\n",
    "print(\"Retrieved Context:\")\n",
    "for i, doc in enumerate(retrieved_docs[:3]):  # Display the first 3 retrieved documents\n",
    "    print(f\"Retrieved Document {i+1}:\")\n",
    "    print(\"Content:\", doc.page_content[:500])  # Show first 500 characters of the retrieved content\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Prompt Generation with RAGPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Pipeline is ready for queries.\n",
      "Generated Prompt:\n",
      "\n",
      "        <|start_header_id|>system<|end_header_id|>\n",
      "        You are a knowledgeable assistant specializing in materials science. Answer each question directly and concisely, providing only the necessary information in a straightforward manner, using only the provided context and conversation history. Do NOT reference the question or instructions in the prompt.\n",
      "        If you lack sufficient information, respond with \"I do not know\". Don't fabricate answers.\n",
      "        <|eot_id|>\n",
      "        <|start_header_id|>user<|end_header_id|>\n",
      "        Question: Can you explain the environmental impact of traditional materials, especially in terms of energy consumption and pollution?\n",
      "        Context: Environmental Impact and Sustainable \n",
      "Materials in Materials Science \n",
      "1. Introduction to Environmental Impact and Sustainable Materials \n",
      "The global demand for materials has grown significantly due to industrialization, population \n",
      "growth, and technological advancements. While materials are essential to modern society, their \n",
      "production and use often come with environmental costs, including resource depletion, energy \n",
      "consumption, pollution, and waste generation. Sustainable materials science seeks to minimize \n",
      "these impacts by developing materials that are environmentally friendly and promoting practices \n",
      "that reduce the overall ecological footprint of material production, usage, and disposal. \n",
      "The concept of sustainability in materials science emphasizes the importance of responsible \n",
      "resource management, reduced emissions, recyclability, and biodegradability. This approach \n",
      "aims to create a \"circular economy,\" where resources are continually reused, and waste is \n",
      "minimized, benefiting both industry and the environment. This document explores the \n",
      "environmental impact of traditional materials, sustainable materials and their applications, and \n",
      "innovative approaches to mitigating environmental challenges. \n",
      " \n",
      "2. Environmental Impact of Traditional Materials \n",
      "The extraction, processing, and disposal of materials like metals, polymers, and ceramics can \n",
      "have significant environmental consequences. Some key impacts include: \n",
      "â€¢<|eot_id|>\n",
      "        <|start_header_id|>assistant<|end_header_id|>\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Test prompt generation with RAGPipeline\n",
    "rag_pipeline = RAGPipeline(vectordb_path=vectordb_path, embedding_model_name=embedding_model_name, model_name=model_name)\n",
    "rag_pipeline.setup_pipeline()  # Initialize and set up the pipeline\n",
    "\n",
    "# Define the question, context, and initialize history for prompt formatting\n",
    "history = \"\"  # Start with an empty history or use some predefined history if available\n",
    "formatted_prompt = rag_pipeline.prompt.format(history=history, context=retrieved_docs[0].page_content, question=question)\n",
    "\n",
    "print(\"Generated Prompt:\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Full Pipeline Test: Get Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " The environmental impact of traditional materials is significant, resulting in resource depletion, energy consumption, pollution, and waste generation. Key impacts include:\n",
      "\n",
      "Resource Depletion: Extraction of non-renewable resources leads to depletion of Earth's reserves.\n",
      "\n",
      "Energy Consumption: Material production is energy-intensive, often derived from fossil fuels, increasing greenhouse gas emissions.\n",
      "\n",
      "Pollution and Emissions: Processing materials releases pollutants into the air, water, and soil, contributing to air pollution.\n",
      "\n",
      "Waste Generation: Industrial processes generate large amounts of waste, including hazardous waste from outdated devices and long-lasting pollution from conventional plastics.\n",
      "\n",
      "These traditional materials have led to a growing emphasis on sustainable alternatives that aim to mitigate resource depletion, reduce emissions, and minimize waste.\n",
      "\n",
      "For further reference, look at:\n",
      "- data/raw\\Environmental Impact and Sustainable Materials in Materials Science.pdf\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Full pipeline test - Generate a response\n",
    "response = rag_pipeline.get_response(question)\n",
    "\n",
    "print(\"Generated Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test multiple questions and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_skeleton.rag import RAGPipeline\n",
    "\n",
    "# Initialize the RAG pipeline\n",
    "vectordb_path = \"vectordb\"  # Replace with your vector database path\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"  # Replace with your model name\n",
    "rag_pipeline = RAGPipeline(vectordb_path=vectordb_path, model_name=model_name)\n",
    "rag_pipeline.setup_pipeline()\n",
    "\n",
    "# Define the questions you want to test with history\n",
    "questions = [\n",
    "    \"Can you explain the environmental impact of traditional materials, especially in terms of energy consumption and pollution?\",\n",
    "    \"Given the environmental concerns with traditional materials, what sustainable alternatives are commonly used to reduce this impact, and how do they compare in terms of recyclability and biodegradability?\",\n",
    "    \"Among the sustainable materials you mentioned, how does green concrete specifically contribute to reducing emissions, and what are some of its unique properties compared to traditional concrete?\",\n",
    "    \"How does the use of green concrete and other sustainable materials align with the principles of the circular economy, and what role does recycling play in this context?\"\n",
    "]\n",
    "\n",
    "# Preview the prompt that will be passed to the LLM for each question\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"Preview of Prompt for Question {i+1}:\")\n",
    "    prompt_text = rag_pipeline.preview_prompt(question)\n",
    "    print(prompt_text)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Optionally, invoke the response to update the history\n",
    "    response = rag_pipeline.get_response(question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
