{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGMgxXFy_aOk"
   },
   "source": [
    "# **RAGSkeleton: A Google Colab Tutorial**\n",
    "\n",
    "**A Modular Framework for Retrieval-Augmented Generation (RAG) Systems**\n",
    "\n",
    "### **Purpose of This Tutorial**\n",
    "\n",
    "This tutorial demonstrates how [**RAGSkeleton**](https://github.com/hasan-sayeed/RAGSkeleton) allows you to:\n",
    "\n",
    "- Parse PDF files, create a vector database, and query it using a RAG pipeline—all within a single framework.\n",
    "- Use any Hugging Face model for text generation, either locally or via the Hugging Face API.\n",
    "- Swap between different LLMs (e.g., `meta-llama/Llama-3.2-3B-Instruct` and `meta-llama/Meta-Llama-3-8B-Instruct`) effortlessly.\n",
    "\n",
    "By default, **RAGSkeleton** is designed as a RAG system for materials science documents. However, users can easily adapt it to any other field by modifying the prompt sent to the LLMs. This modularity makes RAGSkeleton versatile and applicable across diverse domains.\n",
    "\n",
    "By following this tutorial, you’ll learn how to set up and run a Retrieval-Augmented Generation pipeline on your documents using **RAGSkeleton**, ask questions, and get accurate responses grounded in the document content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csXeRpz9AUjA"
   },
   "source": [
    "## **Step 1: Install RAGSkeleton**\n",
    "\n",
    "Install RAGSkeleton directly from PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DB_WwB_jvouy"
   },
   "outputs": [],
   "source": [
    "!pip install rag-skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1TTVq5rAr4V"
   },
   "source": [
    "## **Step 2: Login to Hugging Face**\n",
    "\n",
    "To access any model from the Hugging Face Hub, log in using the huggingface-cli. This step is required if you plan to use the API for larger models or those not available locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUKLjVHHBCUN"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuWU-VIIA4Va"
   },
   "source": [
    "Follow the on-screen instructions to enter your Hugging Face access token. You can obtain the token from your [Hugging Face](https://huggingface.co/) account settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBaY3FaPBKRD"
   },
   "source": [
    "## **Step 3: Mount Google Drive**\n",
    "\n",
    "Mount your Google Drive to access the folder containing your documents. Ensure your PDFs are stored in a folder named `rag_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAiFv8F02Tka"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive to access and store your files\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the path to your folder in Google Drive containing the raw PDF files\n",
    "data_path = \"/content/drive/My Drive/rag_data\"\n",
    "\n",
    "# Define the path to store the vector database created from the documents\n",
    "# This database will be queried by the RAG system to retrieve relevant context for questions\n",
    "vectordb_path = \"/content/drive/My Drive/rag_data/vectordb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV0Wi-D2CEuv"
   },
   "source": [
    "## **Step 4: Process Documents and Create a Vector Database**\n",
    "\n",
    "All parsing and indexing are handled by RAGSkeleton using its DataProcessor module. This step:\n",
    "\n",
    "- Loads the documents from the `rag_data` folder.\n",
    "- Splits the documents into smaller chunks.\n",
    "- Creates a vector database for efficient retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDrLQyQr2cC3"
   },
   "outputs": [],
   "source": [
    "from rag_skeleton.data_processing import DataProcessor\n",
    "\n",
    "# Initialize and process documents\n",
    "data_processor = DataProcessor(data_path=data_path, vectordb_path=vectordb_path)\n",
    "data_processor.process_and_create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uhsobnh5CZE7"
   },
   "source": [
    "## **Step 5: Initialize the RAG Pipeline**\n",
    "\n",
    "The **RAGPipeline** module of RAGSkeleton combines document retrieval and text generation. It supports both local model loading and model loading via the Hugging Face API. For demonstration purposes, we will use API mode to access a larger model, `meta-llama/Meta-Llama-3-8B-Instruct`, via the Hugging Face Hub.\n",
    "\n",
    "Explanation:\n",
    "- **Local Mode(`load_mode='local'`)**: Use a model available locally on your machine.\n",
    "  - Use a model available locally on your machine.\n",
    "  - This is suitable for smaller models that fit on your hardware or when you have the required computational resources.\n",
    "- **API Mode(`load_mode='api'`)**: Access any model from the Hugging Face Hub, ideal for larger models like `meta-llama/Meta-Llama-3-8B-Instruct` that may not fit on your local hardware.\n",
    "  - Allows access to any model from the Hugging Face Hub.\n",
    "  - Useful for larger models that may not fit on local hardware.\n",
    "  - **Note**: You must provide your Hugging Face API token using the `api_token=` parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpgmVzkCFVYr"
   },
   "source": [
    "**Example: Initialize the Pipeline in API Mode**\n",
    "\n",
    "Here’s how to initialize the pipeline in API mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihngkmM34Vj8"
   },
   "outputs": [],
   "source": [
    "from rag_skeleton.rag import RAGPipeline\n",
    "\n",
    "# Initialize the RAG pipeline\n",
    "rag_pipeline = RAGPipeline(\n",
    "    vectordb_path=vectordb_path,  # Default location for vector database\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",  # Example LLM from Hugging Face\n",
    "    load_mode=\"api\",  # 'local' for models on your system; use 'api' for Hugging Face API\n",
    "    api_token='YOUR_API_HERE'   # Replace with your Hugging Face API token\n",
    ")\n",
    "rag_pipeline.setup_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsAQBGC5Flrd"
   },
   "source": [
    "This will set up the RAG pipeline to query your vector database and generate responses using the specified model from the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr7L500vGQLI"
   },
   "source": [
    "**Modularity: Swapping Models**\n",
    "\n",
    "RAGSkeleton is designed with modularity in mind, allowing you to easily swap the model used for text generation. For example:\n",
    "\n",
    "- You could use a smaller model like `meta-llama/Llama-3.2-3B-Instruct` for faster inference with lower hardware requirements.\n",
    "- Alternatively, you can experiment with newer models from the Hugging Face Hub to improve generation quality.\n",
    "Simply change the `model_name` parameter in the above code block to your desired model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dqn_wzP1Gzzs"
   },
   "source": [
    "## **Step 6: Ask Questions**\n",
    "\n",
    "The RAG system is now ready to accept your questions interactively. It will:\n",
    "\n",
    "- Retrieve relevant context from the vector database based on your question.\n",
    "- Generate answers grounded in the document content using the chosen LLM.\n",
    "\n",
    "When you ask a question, the system will:\n",
    "\n",
    "- Retrieve relevant context from the vector database.\n",
    "- Generate a response grounded in that context.\n",
    "- Return the paths of the source documents used in the retrieval.\n",
    "\n",
    "**Note:** For this tutorial, we used materials science documents, and the example outputs reflect content from those documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSnrz-DJHXxG"
   },
   "source": [
    "**Example Usage:**\n",
    "\n",
    "Type your questions when prompted, and type exit to quit the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9_Dwcqw57-oL",
    "outputId": "a074c783-3a7f-4564-9b60-4782f27bb4dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the RAG system! Type 'exit' to end the session.\n",
      "Ask your question: Can you explain the environmental impact of traditional materials, especially in terms of energy consumption and pollution?\n",
      "\n",
      "Response:  The extraction, processing, and disposal of traditional materials like metals, polymers, and ceramics have significant environmental consequences. Some key impacts include:\n",
      "\n",
      "* Resource Depletion: Extracting non-renewable resources, such as metals and fossil fuels, depletes the Earth's reserves.\n",
      "* Energy Consumption: Material production is energy-intensive, requiring substantial energy often derived from fossil fuels, which increases greenhouse gas emissions.\n",
      "* Pollution and Emissions: Processing materials releases pollutants into the air, water, and soil, contributing to air pollution. For example, plastic production emits VOCs and other pollutants, and the cement industry is a significant source of carbon dioxide emissions.\n",
      "* Waste Generation: Industrial processes generate large amounts of waste, including hazardous waste from electronic devices and non-biodegradable plastics.\n",
      "\n",
      "The production and use of traditional materials often lead to environmental costs, including resource depletion, energy consumption, pollution, and waste generation.\n",
      "\n",
      "For further reference, look at:\n",
      "- /content/drive/My Drive/rag_data/Environmental Impact and Sustainable Materials in Materials Science.pdf\n",
      "\n",
      "\n",
      "Ask your question: Given the environmental concerns with traditional materials, what sustainable alternatives are commonly used to reduce this impact, and how do they compare in terms of recyclability and biodegradability?\n",
      "\n",
      "Response:  Sustainable alternatives to traditional materials aim to reduce environmental impact through resource efficiency, lower energy consumption, and minimized waste generation. Some common sustainable materials include:\n",
      "\n",
      "1. Biodegradable Polymers: Derived from renewable resources like corn or sugarcane, these polymers decompose naturally, reducing plastic waste.\n",
      "2. Recycled Materials: Recycling involves reprocessing waste materials into new products, conserving raw materials and energy.\n",
      "3. Bio-based Composites: Combining natural fibers with resins offers a sustainable alternative to synthetic composites.\n",
      "\n",
      "These sustainable materials exhibit varying levels of recyclability and biodegradability:\n",
      "\n",
      "* Biodegradable Polymers: Biodegradable polymers like PLA and PHAs are designed to decompose naturally, reducing pollution from plastic waste.\n",
      "* Recycled Materials: Recycled materials, such as recycled metals, plastics, and paper, can be reused multiple times, reducing the need for raw materials and energy.\n",
      "* Bio-based Composites: While not fully biodegradable, bio-based composites can be recycled or composted, reducing waste and the environmental impact of their production.\n",
      "\n",
      "When compared to traditional materials, sustainable alternatives generally exhibit:\n",
      "\n",
      "* Lower energy consumption: Sustainable materials often require less energy for production, processing, and disposal.\n",
      "* Reduced waste generation: Sustainable materials are designed with recyclability and biodegradability in mind, minimizing waste and pollution.\n",
      "* Conservation of resources: Sustainable materials conserve raw materials and reduce the demand for non-renewable resources.\n",
      "\n",
      "Examples of sustainable materials in different industries include:\n",
      "\n",
      "* Automotive: Lightweight and sustainable materials like recycled aluminum, bio-composites, and natural fiber reinforcements improve fuel efficiency and reduce emissions.\n",
      "* Construction: Green concrete, recycled steel, and bamboo reduce emissions and improve energy efficiency.\n",
      "* Electronics: Sustainable practices involve designing products for easier recycling and using conflict-free minerals, aiming to reduce e-waste.\n",
      "\n",
      "By adopting sustainable materials, industries can significantly reduce their environmental impact, promote resource conservation, and contribute to a more circular economy.\n",
      "\n",
      "For further reference, look at:\n",
      "- /content/drive/My Drive/rag_data/Environmental Impact and Sustainable Materials in Materials Science.pdf\n",
      "\n",
      "\n",
      "Ask your question: exit\n",
      "Exiting the chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Function to interactively ask questions\n",
    "def interactive_chat():\n",
    "    print(\"Welcome to the RAG system! Type 'exit' to end the session.\")\n",
    "    while True:\n",
    "        question = input(\"Ask your question: \")\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Exiting the chatbot. Goodbye!\")\n",
    "            break\n",
    "        response = rag_pipeline.get_response(question)\n",
    "        print(\"\\nResponse:\", response)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Start interactive chat\n",
    "interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
